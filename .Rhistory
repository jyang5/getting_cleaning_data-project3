install.packages(rcurl)
install.packages(rcran)
install.packages(RCurl)
install.packages("RCurl")
install.packages("httr")
library(httr)
oauth_endpoint("github")
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "041594fde597fb240901",
secret = "4ffbc64123105a1b1b889da47a1ba71929b40c36")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
gtoken <- config(token = github_token)
req <- GET("http://api.github.com/users/jtleek/repos", gtoken)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
gtoken <- config(token = github_token, cache=FALSE)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp,cache=FALSE)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp,cache=FALSE)
req <- GET("https://api.github.com/rate_limit", gtoken)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp,cache=FALSE)
?split
library(datasets)
n<-10;
nn<-100
g<-factor(round(n*runif(n*nn)))
g
runif(n*nn)
?runif
g<-factor(round(n*runif(n*nn)))
g
?factor
?split
x<-rnorm(n*nn)+sqrt(as.numeric(g))
x
xg<-splig(x,g)
xg<-split(x,g)
xg
split(x,10)
split(x,1:10)
?gl
traceback()
library(datasets)
data(iris)
iris$Sepal.Length
iris$Species
s<-split(iris,iris$Species)
slapply()
s
lapply(s,mean)
lapply(s,mean(s$virginica))
mean(s$virginica)
s$virginica
lapply(iris$Sepal.Length,mean)
s
lapply(s,function(x) mean(x["Sepal.Length"]))
s["Sepal.Length"]
iris
s
lapply(s,mean)
s
s[Sepal.Length]
s&Sepal.Length]
s$virginica
lapply(s,function(x) colMeans(x[,c("Sepal.Length")])
)
airquality
s<-split(airquality,airquality$Month)
s
lapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
x<-split(iris, iris$Species)
s<-split(iris, iris$Species)
lapply(s, function(x) colMeans(x[, c("Sepal.Length")]))
s
s<-split(airquality,airquality$Month)
s
s
s<-split(iris, iris$Species)
s
s$virginica
colMeans(s$virginica)
colMeans(s$virginica[,"Sepal.Length"])
colMeans(s$virginica[,c("Sepal.Length","Sepal.Width"])
colMeans(s$virginica[,c("Sepal.Length","Sepal.Width")])
apply(iris[,1:4],2,mean)
apply(iris,1,mean)
apply(iris[,1:4],1,mean)
apply(iris,2,mean)
data(mtcars)
?mtcars
mtcars
tapply(mtcars$cyl, mtcars$mpg, mean)
apply(mtcars, 2, mean)
with(mtcars, tapply(mpg, cyl, mean))
with(mtcars, tapply(hp, cyl, mean))
122.28571-209.21429
debug(ls)
ls
?debug
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
209.21429-82.63636
library(Hmisc)
install.packages("knitr")
setwd("/home/jane/Documents/learn/coursera/getting_cleaning_data/project3")
test_data<-read.table("./UCI HAR Dataset/test/X_test.txt")
train_data<-read.table("./UCI HAR Dataset/train/X_train.txt")
test_label<-read.table("./UCI HAR Dataset/test/y_test.txt")
train_label<-read.table("./UCI HAR Dataset/train/y_train.txt")
test_subject<-read.table("./UCI HAR Dataset/test/subject_test.txt")
train_subject<-read.table("./UCI HAR Dataset/train/subject_train.txt")
merged_data<-rbind(train_data,test_data)
merged_label<-rbind(train_label,test_lable)
merged_subject<-rbind(train_subject,test_subject)
names(merged_subject)<-"subject"
names(merged_label)<-"label"
features<-read.table("./UCI HAR Dataset/features.txt")
names(merged_data)<-features$V2
#step1: Merges the training and the test sets to create one data set.
data_set1<-cbind(merged_subject,merged_label)
data_set<-cbind(merged_data,data_set1)
#step2: Extracts only the measurements on the mean and standard deviation for each measurement.
mean_std_feature<-grep("mean\\(\\)|std\\(\\)", features$V2)
columns<-c(as.character(features$V2[mean_std_feature]), "subject", "label" )
data_set<-subset(data_set, select = columns)
#step3: Uses descriptive activity names to name the activities in the data set
activityLabels  <- read.table("./UCI HAR Dataset/activity_labels.txt")
data_set$label<-factor(data_set$label,activityLabels$V1, activityLabels$V2)
#step4: Appropriately labels the data set with descriptive variable names.
names(data_set)<-gsub("^t", "time", names(data_set))
names(data_set)<-gsub("^f", "frequency", names(data_set))
names(data_set)<-gsub("Acc", "Accelerometer", names(data_set))
names(data_set)<-gsub("Gyro", "Gyroscope", names(data_set))
names(data_set)<-gsub("Mag", "Magnitude", names(data_set))
names(data_set)<-gsub("BodyBody", "Body", names(data_set))
#step5: From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
library(plyr);
data_set2<-aggregate(. ~subject + label, data_set, mean)
data_set2<-data_set2[order(data_set2$subject,data_set2$label),]
write.table(data_set2, file = "tidydata.txt",row.name=FALSE)
test_data<-read.table("./UCI HAR Dataset/test/X_test.txt")
train_data<-read.table("./UCI HAR Dataset/train/X_train.txt")
test_label<-read.table("./UCI HAR Dataset/test/y_test.txt")
train_label<-read.table("./UCI HAR Dataset/train/y_train.txt")
test_subject<-read.table("./UCI HAR Dataset/test/subject_test.txt")
train_subject<-read.table("./UCI HAR Dataset/train/subject_train.txt")
merged_data<-rbind(train_data,test_data)
merged_label<-rbind(train_label,test_label)
merged_subject<-rbind(train_subject,test_subject)
names(merged_subject)<-"subject"
names(merged_label)<-"label"
features<-read.table("./UCI HAR Dataset/features.txt")
names(merged_data)<-features$V2
#step1: Merges the training and the test sets to create one data set.
data_set1<-cbind(merged_subject,merged_label)
data_set<-cbind(merged_data,data_set1)
#step2: Extracts only the measurements on the mean and standard deviation for each measurement.
mean_std_feature<-grep("mean\\(\\)|std\\(\\)", features$V2)
columns<-c(as.character(features$V2[mean_std_feature]), "subject", "label" )
data_set<-subset(data_set, select = columns)
#step3: Uses descriptive activity names to name the activities in the data set
activityLabels  <- read.table("./UCI HAR Dataset/activity_labels.txt")
data_set$label<-factor(data_set$label,activityLabels$V1, activityLabels$V2)
#step4: Appropriately labels the data set with descriptive variable names.
names(data_set)<-gsub("^t", "time", names(data_set))
names(data_set)<-gsub("^f", "frequency", names(data_set))
names(data_set)<-gsub("Acc", "Accelerometer", names(data_set))
names(data_set)<-gsub("Gyro", "Gyroscope", names(data_set))
names(data_set)<-gsub("Mag", "Magnitude", names(data_set))
names(data_set)<-gsub("BodyBody", "Body", names(data_set))
#step5: From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
library(plyr);
data_set2<-aggregate(. ~subject + label, data_set, mean)
data_set2<-data_set2[order(data_set2$subject,data_set2$label),]
write.table(data_set2, file = "tidydata.txt",row.name=FALSE)
library(knitr)
knit2html("codebook.Rmd")
library(knitr)
knit2html("codebook.Rmd")
